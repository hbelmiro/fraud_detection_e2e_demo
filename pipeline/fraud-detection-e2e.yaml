# PIPELINE DEFINITION
# Name: fraud-detection-e2e-pipeline
components:
  comp-feature-engineering:
    executorLabel: exec-feature-engineering
    inputDefinitions:
      parameters:
        data_preparation_ok:
          parameterType: BOOLEAN
    outputDefinitions:
      parameters:
        features_ok:
          parameterType: STRING
  comp-prepare-data:
    executorLabel: exec-prepare-data
    inputDefinitions:
      parameters:
        data_preparation_image:
          parameterType: STRING
        job_id:
          parameterType: STRING
    outputDefinitions:
      parameters:
        Output:
          parameterType: BOOLEAN
  comp-register-model:
    executorLabel: exec-register-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
    outputDefinitions:
      parameters:
        model_name:
          parameterType: STRING
        model_version:
          parameterType: STRING
  comp-retrieve-features:
    executorLabel: exec-retrieve-features
    inputDefinitions:
      parameters:
        features_ok:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        output_df:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-serve:
    executorLabel: exec-serve
    inputDefinitions:
      parameters:
        job_id:
          parameterType: STRING
        model_name:
          parameterType: STRING
        model_version_name:
          parameterType: STRING
        rest_predictor_image:
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-feature-engineering:
      container:
        args:
        - '{{$.outputs.parameters[''features_ok''].output_file}}'
        command:
        - sh
        - -c
        - python /app/feast_feature_engineering.py --feature-repo-path=/app/feature_repo
        image: quay.io/hbelmiro/fraud-detection-e2e-demo-feature-engineering-rhoai:latest
    exec-prepare-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - prepare_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef prepare_data(job_id: str, data_preparation_image: str) -> bool:\n\
          \    from kubernetes import client, config\n    from datetime import datetime,\
          \ timedelta\n    import time\n    import logging\n\n    logging.basicConfig(level=logging.INFO)\n\
          \    logger = logging.getLogger(__name__)\n\n    config.load_incluster_config()\n\
          \n    spark_app = {\n        \"apiVersion\": \"sparkoperator.k8s.io/v1beta2\"\
          ,\n        \"kind\": \"SparkApplication\",\n        \"metadata\": {\n  \
          \          \"name\": f\"data-preparation-{job_id}\",\n            \"namespace\"\
          : \"fraud-detection\"\n        },\n        \"spec\": {\n            \"type\"\
          : \"Python\",\n            \"pythonVersion\": \"3\",\n            \"mode\"\
          : \"cluster\",\n            \"image\": data_preparation_image,\n       \
          \     \"imagePullPolicy\": \"Always\",\n            \"mainApplicationFile\"\
          : \"local:///app/main.py\",\n            \"sparkVersion\": \"3.5.5\",\n\
          \            \"restartPolicy\": {\n                \"type\": \"Never\"\n\
          \            },\n            \"driver\": {\n                \"serviceAccount\"\
          : \"spark\",\n                \"cores\": 1,\n                \"coreLimit\"\
          : \"1200m\",\n                \"memory\": \"1g\"\n            },\n     \
          \       \"executor\": {\n                \"cores\": 1,\n               \
          \ \"instances\": 1,\n                \"memory\": \"1g\"\n            }\n\
          \        }\n    }\n\n    k8s_client = client.CustomObjectsApi()\n    k8s_client.create_namespaced_custom_object(\n\
          \        group=\"sparkoperator.k8s.io\",\n        version=\"v1beta2\",\n\
          \        namespace=spark_app[\"metadata\"][\"namespace\"],\n        plural=\"\
          sparkapplications\",\n        body=spark_app\n    )\n\n    job_name = spark_app[\"\
          metadata\"][\"name\"]\n    namespace = spark_app[\"metadata\"][\"namespace\"\
          ]\n\n    timeout_minutes = 5\n    start_time = datetime.now()\n    timeout_time\
          \ = start_time + timedelta(minutes=timeout_minutes)\n\n    while True:\n\
          \        if datetime.now() > timeout_time:\n            logger.error(f\"\
          Timeout reached after {timeout_minutes} minutes waiting for Spark job completion\"\
          )\n            return False\n\n        status = k8s_client.get_namespaced_custom_object_status(\n\
          \            group=\"sparkoperator.k8s.io\",\n            version=\"v1beta2\"\
          ,\n            namespace=namespace,\n            plural=\"sparkapplications\"\
          ,\n            name=job_name\n        )\n\n        application_state = status.get(\"\
          status\", {}).get(\"applicationState\", {}).get(\"state\", \"\")\n     \
          \   logger.info(f\"Current application state: {application_state}\")\n\n\
          \        if application_state == \"COMPLETED\":\n            logger.info(\"\
          Spark job completed successfully\")\n            return True\n        elif\
          \ application_state in [\"FAILED\", \"SUBMISSION_FAILED\", \"INVALIDATING\"\
          ]:\n            logger.error(f\"Spark job failed with state: {application_state}\"\
          )\n            return False\n\n        time.sleep(10)\n\n"
        image: quay.io/hbelmiro/fraud-detection-e2e-demo-pipeline-rhoai:latest
    exec-register-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - register_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef register_model(model: Input[Model]) -> NamedTuple('outputs',\
          \ model_name=str, model_version=str):\n    from model_registry import ModelRegistry\n\
          \n    print(\"uri: \" + model.uri)\n\n    registry = ModelRegistry(\n  \
          \      server_address=\"http://fraud-detection.rhoai-model-registries.svc.cluster.local\"\
          ,\n        port=8080,\n        author=\"fraud-detection-e2e-pipeline\",\n\
          \        user_token=\"non-used\",  # Just to avoid a warning\n        is_secure=False\n\
          \    )\n\n    model_name = \"fraud-detection\"\n    model_version = \"{{workflow.uid}}\"\
          \n\n    registry.register_model(\n        name=model_name,\n        uri=model.uri,\n\
          \        version=model_version,\n        description=\"lorem ipsum\",\n\
          \        model_format_name=\"onnx\",\n        model_format_version=\"1\"\
          ,\n        storage_key=\"mlpipeline-minio-artifact\",\n        metadata={\n\
          \            # can be one of the following types\n            \"int_key\"\
          : 1,\n            \"bool_key\": False,\n            \"float_key\": 3.14,\n\
          \            \"str_key\": \"str_value\",\n        }\n    )\n\n    outputs\
          \ = NamedTuple('outputs', model_name=str, model_version=str)\n    return\
          \ outputs(model_name, model_version)\n\n"
        image: quay.io/hbelmiro/fraud-detection-e2e-demo-pipeline-rhoai:latest
    exec-retrieve-features:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - retrieve_features
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef retrieve_features(features_ok: str, output_df: Output[Dataset]):\n\
          \    import logging\n    from feast import FeatureStore\n    import pandas\
          \ as pd\n    import os\n    from minio import Minio\n    import glob\n \
          \   from pyspark.sql import SparkSession\n\n    def download_artifacts(directory_path,\
          \ dest):\n        logging.info(\"directory_path: {}\".format(directory_path))\n\
          \        logging.info(\"dest: {}\".format(dest))\n\n        client = Minio(\n\
          \            minio_endpoint.replace(\"http://\", \"\").replace(\"https://\"\
          , \"\"),\n            access_key=minio_access_key,\n            secret_key=minio_secret_key,\n\
          \            secure=minio_endpoint.startswith(\"https://\")\n        )\n\
          \n        os.makedirs(dest, exist_ok=True)\n\n        objects = client.list_objects(minio_bucket,\
          \ prefix=directory_path, recursive=True)\n\n        for obj in objects:\n\
          \            file_path = os.path.join(dest, obj.object_name.replace(directory_path,\
          \ \"\").lstrip(\"/\"))\n            os.makedirs(os.path.dirname(file_path),\
          \ exist_ok=True)\n\n            print(f\"Downloading: {obj.object_name}\
          \ -> {file_path}\")\n            client.fget_object(minio_bucket, obj.object_name,\
          \ file_path)\n\n        print(\"Download complete.\")\n\n    def fetch_historical_features_entity_df()\
          \ -> pd.DataFrame:\n        features_repo = \"/app/feature_repo/\"\n   \
          \     store = FeatureStore(repo_path=features_repo)\n\n        directory_path\
          \ = os.path.join(features_repo, \"data\", \"output\", \"entity.csv\")\n\
          \        csv_files = glob.glob(os.path.join(directory_path, 'part-*.csv'))\n\
          \        df_list = [pd.read_csv(file) for file in csv_files]\n\n       \
          \ entity_df = pd.concat(df_list, ignore_index=True)\n        entity_df[\"\
          created_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n        entity_df[\"\
          event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n\n        _features\
          \ = store.get_historical_features(\n            entity_df=entity_df,\n \
          \           features=[\n                \"transactions:distance_from_home\"\
          ,\n                \"transactions:distance_from_last_transaction\",\n  \
          \              \"transactions:ratio_to_median_purchase_price\",\n      \
          \          \"transactions:fraud\",\n                \"transactions:used_chip\"\
          ,\n                \"transactions:used_pin_number\",\n                \"\
          transactions:online_order\",\n                \"transactions:set\"\n   \
          \         ],\n        ).to_df()\n\n        return _features\n\n    logging.basicConfig(\n\
          \        level=logging.INFO,\n    )\n\n    logging.info(\"output_df.path:\
          \ {}\".format(output_df.path))\n\n    minio_endpoint = \"http://minio-service.fraud-detection.svc.cluster.local:9000\"\
          \n    minio_access_key = \"minio\"\n    minio_secret_key = \"minio123\"\n\
          \    minio_bucket = \"mlpipeline\"\n    remote_feature_repo_dir = \"artifacts/feature_repo\"\
          \n\n    (\n        SparkSession.builder\n        .appName(\"FeatureEngineeringSpark\"\
          )\n        .config(\"spark.jars.ivy\", \"/app/.ivy2\")\n        .config(\"\
          spark.driver.memory\", \"1g\")\n        .config(\"spark.executor.memory\"\
          , \"1g\")\n        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.1,com.amazonaws:aws-java-sdk-bundle:1.12.458\"\
          )\n        .config(\"spark.hadoop.fs.s3a.endpoint\", minio_endpoint)\n \
          \       .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\")\n       \
          \ .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\")\n        .config(\"\
          spark.hadoop.fs.s3a.path.style.access\", \"true\")\n        .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\"\
          , \"false\")\n        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\"\
          )\n        .getOrCreate()\n    )\n\n    if not all([minio_endpoint, minio_access_key,\
          \ minio_secret_key, minio_bucket, remote_feature_repo_dir]):\n        raise\
          \ ValueError(\"Missing required environment variables!\")\n\n    if features_ok\
          \ != \"true\":\n        raise ValueError(f\"features not ok [status: {features_ok}]\"\
          )\n\n    local_dest = \"/app/feature_repo\"\n\n    download_artifacts(remote_feature_repo_dir,\
          \ local_dest)\n\n    fetch_historical_features_entity_df().to_csv(output_df.path,\
          \ index=False)\n\n"
        image: quay.io/hbelmiro/fraud-detection-e2e-demo-pipeline-rhoai:latest
    exec-serve:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - serve
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"' && \"\
          $0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef serve(model_name: str, model_version_name: str, job_id: str,\
          \ rest_predictor_image: str):\n    import logging\n    import kserve\n \
          \   from kubernetes import client\n    from kubernetes.client import V1Container\n\
          \    from model_registry import ModelRegistry\n\n    logging.info(\"serving\
          \ model: {}\".format(model_name))\n    logging.info(\"model_version: {}\"\
          .format(model_version_name))\n\n    registry = ModelRegistry(\n        server_address=\"\
          http://fraud-detection.rhoai-model-registries.svc.cluster.local\",\n   \
          \     port=8080,\n        author=\"fraud-detection-e2e-pipeline\",\n   \
          \     user_token=\"non-used\",  # Just to avoid a warning\n        is_secure=False\n\
          \    )\n\n    model = registry.get_registered_model(model_name)\n    model_version\
          \ = registry.get_model_version(model_name, model_version_name)\n\n    inference_service\
          \ = kserve.V1beta1InferenceService(\n        api_version=kserve.constants.KSERVE_GROUP\
          \ + \"/v1beta1\",\n        kind=\"InferenceService\",\n        metadata=client.V1ObjectMeta(\n\
          \            name=model_name + \"-\" + job_id,\n            namespace=kserve.utils.get_default_target_namespace(),\n\
          \            labels={\n                \"modelregistry/registered-model-id\"\
          : model.id,\n                \"modelregistry/model-version-id\": model_version.id\n\
          \            },\n        ),\n        spec=kserve.V1beta1InferenceServiceSpec(\n\
          \            predictor=kserve.V1beta1PredictorSpec(\n                service_account_name=\"\
          kserve-sa\",\n                containers=[\n                    V1Container(\n\
          \                        name=\"inference-container\",\n               \
          \         image=rest_predictor_image,\n                        command=[\"\
          python\", \"predictor.py\"],\n                        args=[\"--model-name\"\
          , model_name, \"--model-version\", model_version_name]\n               \
          \     )\n                ]\n            )\n        ),\n    )\n    ks_client\
          \ = kserve.KServeClient()\n    ks_client.create(inference_service)\n\n"
        image: quay.io/hbelmiro/fraud-detection-e2e-demo-pipeline-rhoai:latest
    exec-train-model:
      container:
        args:
        - --training-data-url
        - '{{$.inputs.artifacts[''dataset''].uri}}'
        - --model
        - '{{$.outputs.artifacts[''model''].path}}'
        command:
        - python
        - /app/train.py
        image: quay.io/hbelmiro/fraud-detection-e2e-demo-train-rhoai:latest
pipelineInfo:
  name: fraud-detection-e2e-pipeline
root:
  dag:
    tasks:
      feature-engineering:
        cachingOptions: {}
        componentRef:
          name: comp-feature-engineering
        dependentTasks:
        - prepare-data
        inputs:
          parameters:
            data_preparation_ok:
              taskOutputParameter:
                outputParameterKey: Output
                producerTask: prepare-data
        taskInfo:
          name: feature-engineering
      prepare-data:
        cachingOptions: {}
        componentRef:
          name: comp-prepare-data
        inputs:
          parameters:
            data_preparation_image:
              runtimeValue:
                constant: quay.io/hbelmiro/fraud-detection-e2e-demo-data-preparation-rhoai:latest
            job_id:
              runtimeValue:
                constant: '{{$.pipeline_job_uuid}}'
        taskInfo:
          name: prepare-data
      register-model:
        cachingOptions: {}
        componentRef:
          name: comp-register-model
        dependentTasks:
        - train-model
        inputs:
          artifacts:
            model:
              taskOutputArtifact:
                outputArtifactKey: model
                producerTask: train-model
        taskInfo:
          name: register-model
      retrieve-features:
        cachingOptions: {}
        componentRef:
          name: comp-retrieve-features
        dependentTasks:
        - feature-engineering
        inputs:
          parameters:
            features_ok:
              taskOutputParameter:
                outputParameterKey: features_ok
                producerTask: feature-engineering
        taskInfo:
          name: retrieve-features
      serve:
        cachingOptions: {}
        componentRef:
          name: comp-serve
        dependentTasks:
        - register-model
        inputs:
          parameters:
            job_id:
              runtimeValue:
                constant: '{{$.pipeline_job_uuid}}'
            model_name:
              taskOutputParameter:
                outputParameterKey: model_name
                producerTask: register-model
            model_version_name:
              taskOutputParameter:
                outputParameterKey: model_version
                producerTask: register-model
            rest_predictor_image:
              runtimeValue:
                constant: quay.io/hbelmiro/fraud-detection-e2e-demo-rest-predictor-rhoai:latest
        taskInfo:
          name: serve
      train-model:
        cachingOptions: {}
        componentRef:
          name: comp-train-model
        dependentTasks:
        - retrieve-features
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: output_df
                producerTask: retrieve-features
        taskInfo:
          name: train-model
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0
